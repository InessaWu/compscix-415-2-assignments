---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Inessa Wu"
date: "March 27, 2018"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library (tidyverse)
library (rmarkdown)
library (mosaicData)
library (lubridate)
library(broom)
library(rpart)
library(partykit)
library(ROCR)
library(randomForest)
library(modelr)
```

###Bootstrapping

####Question 1.

```{r message=FALSE}

#Loading titanic file

file_path <- 'C:/Users/ipodvorna/Documents/compscix-415-2-assignments/compscix-415-2-assignments/titanic.csv'
titanic_data <- read_delim(file = file_path, delim = ",")

glimpse(titanic_data)
```


```{r}
#Convert all character columns into unordered factors and Survived column into an unordered factor

titanic_data <- titanic_data %>% mutate(Survived = as.factor(Survived), 
                                        Name = as.factor(Name), 
                                        Sex = as.factor(Sex), 
                                        Ticket = as.factor(Ticket), 
                                        Cabin = as.factor(Cabin), 
                                        Embarked = as.factor(Embarked), 
                                        Pclass = as.factor(Pclass), 
                                        SibSp = as.factor(SibSp), Parch = as.factor(Parch))

#Take a glimpse of the data to confirm that all of the columns were converted correctly

glimpse(titanic_data)
```

####Question 2.

```{r}
#Take 100 bootstrap samples of data

titanic_boot <- bootstrap(data = titanic_data, n = 100)

#Convert to tibble

titanic_boot <- as.tibble(titanic_boot)

#Confirm that the result is a tibble with a list column of resample objects - each resample object is a bootstrap sample of the titanic dataset

head (titanic_boot)

glimpse (titanic_boot$strap[[1]])
```

####Question 3.

Output of the distinct count below confirms that bootstrap samples are in fact bootsrap since it varies from sample to sample which means that some of the rows in the bootstrap samples repeat (not unique)
```{r}
#Use n_distinct() from dplyr to confirm that some of the bootstrap samples are in fact bootstrap samples

as.tibble(titanic_boot$strap[[1]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[2]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[3]]) %>% n_distinct()
```

####Question 4.

```{r}
age_mean <- function(titanic_boot) {
  data <- as.tibble(titanic_boot) # convert input data set to a tibble
  mean_age <- mean(data$Age, na.rm = TRUE) # take the mean of Age, remove NAs
  return(mean_age) # return the mean value of Age from data
}


# loop through the 100 bootstrap samples and use the age_mean()
# function
all_means <- rep(NA, 100)

# start the loop
for(i in 1:100) {
  all_means[i] <- age_mean(titanic_boot$strap[[i]])
}

# take a look at some of the means you calculated from your samples
head(all_means)

# convert to a tibble so we can use if for plotting
all_means <- tibble(all_means = all_means)
```

```{r}
#Plot histogram of all means

ggplot(all_means)+
  geom_histogram(mapping = aes(x=all_means), bins=10)
```


```{r}
#Calculate standard error of bootstrap sample means
all_means %>% summarize(sample_SE = sd(all_means))
```

```{r}
titanic_data1 <- titanic_data %>% filter(!is.na(Age))
theor_SE <- sd(titanic_data1$Age)/sqrt(length(titanic_data1$Age))

print(theor_SE)
```

The standard deviation of sample means is 0.541 comparing to data set standard error of 0.544. These values are very close, in line with Central Limit theorem fundamentals.

###Random forest

####Question 1.

```{r}
#Randomly split data into training and testing data sets
set.seed(987)

titanic_model_data <- resample_partition(titanic_data, c(test = 0.3, train = 0.7))
titanic_train_set <- as.tibble(titanic_model_data$train)
titanic_test_set <- as.tibble(titanic_model_data$test)
```

####Question 2.

Compared to last week's decision tree which only contained three features, the decision tree below has many more nodes. The first split remained the same - Sex. However, Age has been identified as one of the important node splits. For men now it's visible that children under 6.5 years of age had a much higher probaliity of survival.

```{r}
# Fit a decision tree to train_set Pclass, Sex, Age, SibSp, Parch,  Fare, Embarked as the features
tree_mod <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = titanic_train_set)

#Plot the tree using
plot(as.party(tree_mod))
```

####Question 3.

```{r}
# Fit a random forest using Pclass, Sex, Age, SibSp,  Parch, Fare, Embarked as the features. Use 500 trees and sample four features at each split.
rf_mod <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
                         data = titanic_train_set, 
                         ntrees = 500, 
                         mtry = 4, 
                         na.action = na.roughfix)
```

####Question 4.

Random forest model performed better, with greater area under the curve - 0.81 for random forest comparing to 0.79 for decison tree.

```{r}
rf_preds <- predict(rf_mod, newdata = titanic_test_set, type = 'prob')[,2]
tree_preds <- predict(tree_mod, newdata = titanic_test_set)[,2]

pred_rf <- prediction(predictions = rf_preds, labels = titanic_test_set$Survived)
pred_tree <- prediction(predictions = tree_preds, labels = titanic_test_set$Survived)

# calculate the AUC
auc_rf <- performance(pred_rf, measure = "auc")
auc_tree <- performance(pred_tree, measure = "auc")
```

####Question 5.

```{r}
# get the FPR and TPR for the logistic model
perf_rf <- performance(pred_rf, measure = 'tpr', x.measure = 'fpr')
perf_rf_tbl <- tibble(perf_rf@x.values[[1]], perf_rf@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_rf_tbl) <- c('fpr', 'tpr')

# get the FPR and TPR for the tree model
perf_tree <- performance(pred_tree, measure = 'tpr', x.measure = 'fpr')
perf_tree_tbl <- tibble(perf_tree@x.values[[1]], perf_tree@y.values[[1]])

# Change the names of the columns of the tibble
names(perf_tree_tbl) <- c('fpr', 'tpr')

combo_models <- bind_rows("Random forest" = perf_rf_tbl, "Decision tree" = perf_tree_tbl, .id = "models")

# Plotting function for plotting a nice ROC curve using ggplot
plot_roc <- function(perf_tbl) {
  p <- ggplot(data = combo_models, aes(x = fpr, y = tpr, color = models)) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  labs(x = 'False positive rate', y = 'True positive rate') +
  theme_bw()
  return(p)
}

# Create the ROC curves using the function we created above
plot_roc(combo_models)

```

####Question 6.

Random forest model performs better than decision tree with the tradeoff between true positive and false positive and lower rate than the decision tree.

At true positive rate of approximately 0.75, the approximate false positive rate for is as follows:
for decision tree - roughly 0.33; for random forest - roughly 0.16

















