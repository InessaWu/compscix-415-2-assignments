---
title: "COMPSCIX 415.2 Homework 7"
author: "Inessa Wu"
date: "March 13, 2018"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library (tidyverse)
library (rmarkdown)
library (mosaicData)
library (lubridate)
library(broom)
```

###Exercise 1

Loading train.csv data set. Dataset contains 1460 observations and 81 variables (columns)

```{r message=FALSE}
file_path <- 'C:/Users/ipodvorna/Documents/compscix-415-2-assignments/compscix-415-2-assignments/train.csv'
housing_train_data <- read_delim(file = file_path, delim = ",")
```

###Exercise 2

Splitting data into training and test data sets (70/30)

```{r}
# Setting a seed to guarantee that the same random sample is
# generated every time, so long as the same seed is set beforehand

set.seed(29283)

# Creating training data set - 70% of data
train_set <- housing_train_data %>% sample_frac(.7)

# Assigning the remaining 30% of data to testing data set
test_set <- housing_train_data %>% filter(!(Id %in% train_set$Id))
```

###Exercise 3


```{r}
# Fit a model with intercept only
mod_0 <- lm(SalePrice ~ 1, data = train_set)

# The average SalePrice is equal to our model's coefficient at $182,176
mean(train_set$SalePrice)
tidy(mod_0)

# R-squared is 0
glance(mod_0)
```

###Exercise 4

Before fitting the model:

1. What kind of relationship will these features have with our target? 

Neighborhood: Physical locations within Ames city limits
GrLivArea: Above grade (ground) living area square feet
OverallQual: Overall material and finish quality

I expect GrLivArea and OverallQual to be directly correlated with the sales price. Neighborhood could be either directly or inversly correlated with the sales price, depending on the how good the neigborhood is perceived to be.

2. Can the relationship be estimated linearly?

Based on plots below, a linear realtionship could be estimated between sales price and GrLivArea as well as sales price and OverallQual

```{r}
# Plot relationship between sales price and GrLivArea

ggplot(data=train_set)+
  geom_point(mapping = aes(x=GrLivArea, y=SalePrice, color=Neighborhood))
```


```{r}
# Plot relationship between sales price and OverallQual

ggplot(data=train_set)+
  geom_point(mapping = aes(x=OverallQual, y=SalePrice, color=Neighborhood))
```

```{r}
# Plot relationship between sales price and OverallQual

ggplot(data=train_set)+
  geom_point(mapping = aes(x=reorder(Neighborhood,SalePrice, FUN=mean), y=SalePrice))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(x="Neighborhood")
```

```{r}
#Fit a regression model using GrLivArea, OverallQual, and Neighborhood as the features
mod_train_regr <- lm(SalePrice ~ GrLivArea + OverallQual + Neighborhood, data = train_set)

# Output coefficients
tidy(mod_train_regr)

# Output R-squared
glance(mod_train_regr)
```

Coefficients on GrLivArea and OverallQual can be interpreted in the follwoing way: 
For every above grade (ground) living area square feet increase Sales Price of the house goes up by, an average, $62.78 and for every point increase in overall material and finish quality Sales Price increases by $21,692.

Coefficient on NeighborhoodBrkSide can be interprested as follows: Location of the house in BrkSide heighborhood decrease Sales Price by $14,064, on average.

GrLivArea and OverallQual are significant as supported by p-values that are close to 0. However, significance of Neighborhood varies, with majority of neightborhoods lacking significance. 

All three features are practically significant. Wilingess to pay depends on the size of the house, the quality of the build and it's location. However, neighborhoods could potentially be clustered into city regions to streamline the model.

This model is a fairly good fit to the training set since it explains roughly 81% of variability (R-squared). 

###Exercise 5

Calculate RMSE from applying regression model to test set
```{r}
test_predictions <- predict(mod_train_regr, newdata = test_set)

rmse <- sqrt(mean(test_set$SalePrice - test_predictions)^2)
print(rmse)
```
Calculate RMSE from applying mean model to test set
```{r}
test_predictions <- predict(mod_0, newdata = test_set)

rmse <- sqrt(mean(test_set$SalePrice - test_predictions)^2)
print(rmse)
```
RMSE from mean model is smaller than RMSE from the regression model, implying overfitting of train data. Regression model has too much bias and, therefore, is not appropriate in this case.

###Exercise 6

```{r}
#Fit a regression model using GrLivArea, OverallQual, and YearBuilt as the features
mod_train_regr_b <- lm(SalePrice ~ GrLivArea + OverallQual + LotArea +KitchenQual, data = train_set)

# Output coefficients
tidy(mod_train_regr_b)

# Output R-squared
glance(mod_train_regr_b)
```
Calculate RMSE from applying regression model to test set
```{r}
test_predictions <- predict(mod_train_regr_b, newdata = test_set)

rmse <- sqrt(mean(test_set$SalePrice - test_predictions)^2)
print(rmse)
```
Yeah!!!!! Kitchen quality matters - including Lot Area and Kitchen Quality explains 80% of variablity and produces 2208 (much smaller than mean) RMSE

###Exercise 7

One downside of the linear model is that it is sensitive to unusual values because the distance incorporates a squared term. Fit a linear model to the simulated data below, and visualise the results. Rerun a few times to generate different simulated datasets. What do you notice about the model?

```{r}
sim1a <- tibble(
  x = rep(1:10, each = 3),
  y = x * 1.5 + 6 + rt(length(x), df = 2)
)
```



